{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a805b0",
   "metadata": {
    "id": "ae398823"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for data manipulation, visualization, and machine learning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "# Scikit-learn libraries for machine learning algorithms and model evaluation\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# XGBoost and optimization tools\n",
    "import xgboost as xgb\n",
    "from skopt import gbrt_minimize # Bayesian Optimization with GBM as surrogate\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import forest_minimize # Bayesian Optimization with RF as surrogate\n",
    "from skopt import gp_minimize\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afcb6f",
   "metadata": {
    "id": "7d312a9f"
   },
   "outputs": [],
   "source": [
    "# Importing ROC-related libraries for calculating and plotting ROC curves\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings to prevent cluttering the output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba5d02b",
   "metadata": {},
   "source": [
    "# Reading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2424d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the CSV file and transpose it. the dataset contains microRNA expression data\n",
    "\n",
    "data_all = pd.read_csv(\"common_mirs_exp.csv\", index_col=\"Unnamed: 0\").T\n",
    "data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a72839",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all[\"disease\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596d3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test set from a tab-delimited file and transpose it\n",
    "\n",
    "=pd.read_table('GSE29532_mirs_expression.txt').T\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f4dd1e",
   "metadata": {
    "id": "b6fc5532"
   },
   "outputs": [],
   "source": [
    "# Define scoring metrics for cross-validation (accuracy and ROC AUC)\n",
    "\n",
    "scoring = ['accuracy', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49c735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y) in the training dataset\n",
    "\n",
    "X = data_all.drop([\"disease\"], axis=1).astype(float)\n",
    "y = data_all[\"disease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test set by separating the features (X_test) and target (y_test)\n",
    "\n",
    "X_test = test_set.drop(['status'], axis = 1).astype(float)\n",
    "y_test = test_set['status']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e8ba2",
   "metadata": {},
   "source": [
    "# Voters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0970b36a",
   "metadata": {},
   "source": [
    "## Preset Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca93166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradientBoostingClassifier and perform cross-validation with Stratified KFold\n",
    "\n",
    "GB=GradientBoostingClassifier(random_state=1)\n",
    "cv=StratifiedKFold(n_splits=10)\n",
    "scores = cross_validate(GB, X, y, scoring=scoring, cv=cv, n_jobs=-1, \n",
    "                        return_train_score=True, return_estimator=True)\n",
    "scores1=pd.DataFrame(scores)\n",
    "result=pd.DataFrame(scores1.mean(axis=0)[2:8], columns=['Gradiant Boosting']).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2033e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Gradient Boosting model on the training data and evaluate its performance on both training and test sets\n",
    "GB = GradientBoostingClassifier(random_state=1)\n",
    "GB.fit(X, y)\n",
    "GB.score(X, y), GB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set and visualize the confusion matrix for the predictions\n",
    "\n",
    "y_pred=GB.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred,labels=['Healthy', \"MI\"])\n",
    "df_cm=pd.DataFrame(conf_mat,index=[i for i in ['Healthy', \"MI\"]],columns=[i for i in ['Predicted Healthy', 'Predicted MI']])\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"RdBu\", cbar=False, square=True, annot_kws={'size': 22});\n",
    "plt.savefig('Raw_GB_10.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report for Gradient Boosting predictions\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffafc0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and cross-validate SVC with RBF kernel\n",
    "\n",
    "SVC = SVC(random_state=1) \n",
    "cv=StratifiedKFold(n_splits=10)\n",
    "#cv=cv_generator(10, dfs, 1)\n",
    "scores = cross_validate(SVC, X, y, scoring=scoring, cv=cv, n_jobs=-1, \n",
    "                        return_train_score=True, return_estimator=True)\n",
    "scores1=pd.DataFrame(scores)\n",
    "result=pd.DataFrame(scores1.mean(axis=0)[2:8], columns=['SVC']).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a967d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and cross-validate XGBoost classifier\n",
    "\n",
    "XGB = XGBClassifier(random_state=1)\n",
    "cv=StratifiedKFold(n_splits=10)\n",
    "scores = cross_validate(XGB, X, y, scoring=scoring, cv=cv, n_jobs=-1, \n",
    "                        return_train_score=True, return_estimator=True)\n",
    "scores1=pd.DataFrame(scores)\n",
    "result=pd.DataFrame(scores1.mean(axis=0)[2:8], columns=['XGBoost']).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43ef71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report for XGBoost predictions\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c339f9",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ff073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the target labels (encode Healthy/MI as 0/1)\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "y_temp = label.fit_transform(y)\n",
    "y_temp = pd.get_dummies(y_temp)\n",
    "y_temp.columns = ['Healthy', 'MI']\n",
    "y = y_temp.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf9d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified KFold for ROC analysis\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d791d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC analysis using Gradient Boosting classifier\n",
    "\n",
    "classifier = GradientBoostingClassifier(random_state=1)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_gb = np.mean(tprs, axis=0)\n",
    "mean_tpr_gb[-1] = 1.0\n",
    "mean_auc_gb = auc(mean_fpr, mean_tpr_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e7e9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC analysis using XGBoost classifier\n",
    "\n",
    "classifier = XGBClassifier(random_state=1)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_xgb = np.mean(tprs, axis=0)\n",
    "mean_tpr_xgb[-1] = 1.0\n",
    "mean_auc_xgb = auc(mean_fpr, mean_tpr_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ddd838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC analysis using SVC classifier\n",
    "\n",
    "classifier = SVC(random_state=1)\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_svc = np.mean(tprs, axis=0)\n",
    "mean_tpr_svc[-1] = 1.0\n",
    "mean_auc_svc = auc(mean_fpr, mean_tpr_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad9aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the plot for comparing ROC curves of different models (GB, XGB, SVM)\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "\n",
    "# Plotting ROC curve for Gradient Boosting model\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_gb,\n",
    "    color=\"red\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"GB\", round(mean_auc_gb, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Plotting ROC curve for XGBoost model\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_xgb,\n",
    "    color=\"green\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"XGB\", round(mean_auc_xgb, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Plotting ROC curve for SVM model\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_svc,\n",
    "    color=\"blue\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"SVM\", round(mean_auc_svc, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "# Plotting a reference diagonal line representing random chance (AUC=0.5)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 24)\n",
    "plt.ylabel('True Positive Rate', fontsize = 24)\n",
    "plt.legend(loc=\"lower right\", prop={'size':24})\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.savefig(\"base_models.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab0d1f",
   "metadata": {},
   "source": [
    "## Hypertuning Voter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets (70/30) with stratified sampling to maintain class proportions\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0225d10",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd50642",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34bc4300",
    "outputId": "925607d2-3ac4-406d-df31-7b633c1f3379"
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameter space for the SVM model\n",
    "\n",
    "param_grid = [\n",
    "    Real(0.1, 1000, prior='log-uniform', name='C'),\n",
    "    Real(0.0001, 1, prior='log-uniform', name=\"gamma\"),\n",
    "    Categorical(['linear', 'rbf', 'poly'], name=\"kernel\"),\n",
    "    Integer(2, 5, name=\"degree\"),\n",
    "\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e4335",
   "metadata": {
    "id": "b1622753"
   },
   "outputs": [],
   "source": [
    "# Initialize the SVM model with class weight 'balanced' to handle class imbalance\n",
    "\n",
    "gbm = SVC(random_state=1, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d7dd",
   "metadata": {
    "id": "a0fa5f8e"
   },
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement for scikit-optimize.\n",
    "\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            n_jobs=6,\n",
    "            scoring='recall'))\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8009bc",
   "metadata": {
    "id": "85d844c9"
   },
   "outputs": [],
   "source": [
    "# using GBMs as surrogate for f(x)\n",
    "\n",
    "gbm_ = gbrt_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=100, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    "    n_jobs=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52d29da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "1c5c8cba",
    "outputId": "d3e8d752-2fb5-4b70-c90e-8b6c932e1fe9"
   },
   "outputs": [],
   "source": [
    "# Print the best score found by the optimizer (negated because of minimization)\n",
    "\n",
    "\"Best score=%.4f\" % gbm_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best parameters from the optimization result and set them to the SVM model\n",
    "\n",
    "best_params = dict(zip([dim.name for dim in param_grid], gbm_.x))\n",
    "SVC = gbm.set_params(**best_params)\n",
    "\n",
    "# Cross-validate the model with the best parameters using 5-fold stratified sampling\n",
    "cv=StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(SVC, X, y, scoring=scoring, cv=cv, n_jobs=-1, \n",
    "                        return_train_score=True, return_estimator=True)\n",
    "scores1=pd.DataFrame(scores)\n",
    "result=pd.DataFrame(scores1.mean(axis=0)[2:6], columns=['SVC']).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054b0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SVM model with optimized parameters on the training data\n",
    "\n",
    "SVC.fit(X_train, y_train)\n",
    "SVC.score(X_train, y_train), SVC.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee803ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the validation set\n",
    "\n",
    "y_pred=SVC.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417959f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the SVC model to the entire dataset and test it on the test set\n",
    "\n",
    "SVC.fit(X, y)\n",
    "SVC.score(X, y), SVC.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0fe7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set and create a confusion matrix\n",
    "\n",
    "y_pred=SVC.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred,labels=['Healthy', \"MI\"])\n",
    "df_cm=pd.DataFrame(conf_mat,index=[i for i in ['Healthy', \"MI\"]],columns=[i for i in ['Predicted Healthy', 'Predicted MI']])\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"RdBu\", cbar=False, square=True, annot_kws={'size': 22});\n",
    "plt.savefig('Hyper_SVC-poly_10.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84878a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2dd854",
   "metadata": {},
   "source": [
    "### Gradiant Boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = [\n",
    "    Integer(10, 120, name=\"n_estimators\"),\n",
    "    Integer(2, 5, name=\"max_depth\"),\n",
    "    Real(0.0001, 0.1, prior='log-uniform', name='learning_rate'),\n",
    "    Categorical(['deviance', 'exponential'], name=\"loss\"),\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59411dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gradient boosting classifier\n",
    "\n",
    "gbm = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e3d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement for scikit-optimize.\n",
    "\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            n_jobs=-4,\n",
    "            scoring='recall')\n",
    "    )\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df11cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbrt_minimize performs by Bayesian Optimization \n",
    "# using GBMs as surrogate for f(x)\n",
    "\n",
    "gbm_ = gbrt_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=100, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    "    n_jobs=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function value at the minimum.\n",
    "# note that it is the negative of the accuracy\n",
    "\n",
    "\"Best score=%.4f\" % gbm_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf7f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = dict(zip([dim.name for dim in param_grid], gbm_.x))\n",
    " = gbm.set_params(**best_params)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# cv=cv_generator(10, dfs, 1)\n",
    "scores = cross_validate(\n",
    "    GB,\n",
    "    X,\n",
    "    y,\n",
    "    scoring=scoring,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "scores1 = pd.DataFrame(scores)\n",
    "result = pd.DataFrame(scores1.mean(axis=0)[2:6], columns=[\"GB\"]).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB.fit(X_train, y_train)\n",
    "GB.score(X_train, y_train), GB.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447815cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=GB.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ed331",
   "metadata": {},
   "outputs": [],
   "source": [
    "GB.fit(X, y)\n",
    "GB.score(X, y), GB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=GB.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred,labels=['Healthy', \"MI\"])\n",
    "df_cm=pd.DataFrame(conf_mat,index=[i for i in ['Healthy', \"MI\"]],columns=[i for i in ['Predicted Healthy', 'Predicted MI']])\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"RdBu\", cbar=False, square=True, annot_kws={'size': 22});\n",
    "plt.savefig('Hyper_GB_10.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2de7da",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ca222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "\n",
    "param_grid = [\n",
    "    Integer(10, 200, name='n_estimators'),\n",
    "    Integer(2, 10, name='max_depth'),\n",
    "    Real(0.01, 0.99, name='learning_rate'),\n",
    "    Categorical(['gbtree', 'dart'], name='booster')\n",
    "]\n",
    "\n",
    "# Scikit-optimize parameter grid is a list\n",
    "type(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca86dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the gradient boosting classifier\n",
    "\n",
    "gbm = xgb.XGBClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5698e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We design a function to maximize the accuracy, of a GBM,\n",
    "# with cross-validation\n",
    "\n",
    "# the decorator allows our objective function to receive the parameters as\n",
    "# keyword arguments. This is a requirement of Scikit-Optimize.\n",
    "@use_named_args(param_grid)\n",
    "def objective(**params):\n",
    "    \n",
    "    # model with new parameters\n",
    "    gbm.set_params(**params)\n",
    "\n",
    "    # optimization function (hyperparam response function)\n",
    "    value = np.mean(\n",
    "        cross_val_score(\n",
    "            gbm, \n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=5,\n",
    "            n_jobs=6,\n",
    "            scoring='recall')\n",
    "    )\n",
    "\n",
    "    # negate because we need to minimize\n",
    "    return -value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b1c9fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using a Marten Kernel\n",
    "\n",
    "gp_ = gp_minimize(\n",
    "    objective, # the objective function to minimize\n",
    "    param_grid, # the hyperparameter space\n",
    "    n_initial_points=10, # the number of points to evaluate f(x) to start of\n",
    "    acq_func='EI', # the acquisition function\n",
    "    n_calls=200, # the number of subsequent evaluations of f(x)\n",
    "    random_state=0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c998752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function value at the minimum.\n",
    "# note that it is the negative of the accuracy\n",
    "\n",
    "\"Best score=%.4f\" % gp_.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = dict(zip([dim.name for dim in param_grid], gbm_.x))\n",
    "XGB = gbm.set_params(**best_params)\n",
    "\n",
    "cv=StratifiedKFold(n_splits=5)\n",
    "#cv=cv_generator(10, dfs, 1)\n",
    "scores = cross_validate(XGB, X, y, scoring=scoring, cv=cv, n_jobs=-1, \n",
    "                        return_train_score=True, return_estimator=True)\n",
    "scores1=pd.DataFrame(scores)\n",
    "result=pd.DataFrame(scores1.mean(axis=0)[2:6], columns=['XGB']).T\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f84bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.fit(X_train, y_train)\n",
    "XGB.score(X_train, y_train), XGB.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=XGB.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB.fit(X, y)\n",
    "XGB.score(X, y), XGB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e1f7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=XGB.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test,y_pred,labels=['Healthy', \"MI\"])\n",
    "df_cm=pd.DataFrame(conf_mat,index=[i for i in ['Healthy', \"MI\"]],columns=[i for i in ['Predicted Healthy', 'Predicted MI']])\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"RdBu\", cbar=False, square=True, annot_kws={'size': 22});\n",
    "plt.savefig('Hyper_XGB_10.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277ce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd17c04",
   "metadata": {},
   "source": [
    "# Voting with Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a77bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of estimators for the VotingClassifierestimator = [] \n",
    "estimator.append(('GB', GB)) \n",
    "estimator.append(('XGP', XGB)) \n",
    "estimator.append(('SVC', SVC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VotingClassifier with hard voting method\n",
    "\n",
    "hard_voting = VotingClassifier(estimators = estimator, voting ='hard') \n",
    "hard_voting.fit(X_train, y_train)\n",
    "hard_voting.score(X_train, y_train), hard_voting.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6884b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate on validation set\n",
    "\n",
    "y_pred=hard_voting.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad233d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the VotingClassifier on the entire training set and evaluate on test set\n",
    "\n",
    "hard_voting = VotingClassifier(estimators = estimator, voting ='hard') \n",
    "hard_voting.fit(X, y) \n",
    "hard_voting.score(X, y), hard_voting.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and generate confusion matrix for the test set\n",
    "\n",
    "y_pred = hard_voting.predict(X_test) \n",
    "conf_mat = confusion_matrix(y_test,y_pred,labels=['Healthy', \"MI\"])\n",
    "df_cm=pd.DataFrame(conf_mat,index=[i for i in ['Healthy', \"MI\"]],columns=[i for i in ['Predicted Healthy', 'Predicted MI']])\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.tick_params(axis='both', which='major', labelsize=17)\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"RdBu\", cbar=False, square=True, annot_kws={'size': 22});\n",
    "plt.savefig('Hyper_vote_10.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887891f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a02427",
   "metadata": {},
   "source": [
    "## ROC for Hypertuned Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a87957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable and prepare it for ROC curve plotting\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "y_temp = label.fit_transform(y)\n",
    "y_temp = pd.get_dummies(y_temp)\n",
    "y_temp.columns = ['Healthy', 'MI']\n",
    "y = y_temp.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdc2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f79a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Gradient Boosting\n",
    "\n",
    "classifier = GB\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_gb = np.mean(tprs, axis=0)\n",
    "mean_tpr_gb[-1] = 1.0\n",
    "mean_auc_gb = auc(mean_fpr, mean_tpr_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for XGBoost\n",
    "\n",
    "classifier = XGB\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_xgb = np.mean(tprs, axis=0)\n",
    "mean_tpr_xgb[-1] = 1.0\n",
    "mean_auc_xgb = auc(mean_fpr, mean_tpr_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Support Vector Classification\n",
    "\n",
    "classifier = SVC\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 9))\n",
    "for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "    classifier.fit(X.iloc[train, ], y[train])\n",
    "    y_pred=classifier.predict(X.iloc[test, ])\n",
    "    viz = RocCurveDisplay.from_estimator(\n",
    "        classifier,\n",
    "        X.iloc[test, ],\n",
    "        y[test],\n",
    "        name=\"_\",\n",
    "        alpha=0,\n",
    "        lw=0,\n",
    "        ax=ax,\n",
    "    )\n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "\n",
    "mean_tpr_svc = np.mean(tprs, axis=0)\n",
    "mean_tpr_svc[-1] = 1.0\n",
    "mean_auc_svc = auc(mean_fpr, mean_tpr_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Hard Voting Ensemble\n",
    "\n",
    "mean_tpr_vote = np.mean([mean_tpr_gb, mean_tpr_svc, mean_tpr_xgb], axis=0)\n",
    "mean_tpr_vote[-1] = 1.0\n",
    "mean_auc_vote = auc(mean_fpr, mean_tpr_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48139e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC Curves for individual models and ensemble\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_gb,\n",
    "    color=\"red\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"GB\", round(mean_auc_gb, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_xgb,\n",
    "    color=\"green\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"XGB\", round(mean_auc_xgb, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_svc,\n",
    "    color=\"blue\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"SVM\", round(mean_auc_svc, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr_vote,\n",
    "    color=\"gold\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"HVE\", round(mean_auc_vote, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 24)\n",
    "plt.ylabel('True Positive Rate', fontsize = 24)\n",
    "plt.legend(loc=\"lower right\", prop={'size':24})\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.savefig(\"tuned_models_val2.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3cfa3",
   "metadata": {},
   "source": [
    "## ROC on REAL TEST SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840eb96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test target variable\n",
    "\n",
    "label = LabelEncoder()\n",
    "\n",
    "y_temp = label.fit_transform(y_test)\n",
    "y_temp = pd.get_dummies(y_temp)\n",
    "y_temp.columns = ['Healthy', 'MI']\n",
    "y_test = y_temp.iloc[:, 1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fpr = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Gradient Boosting on test set\n",
    "\n",
    "classifier = GB\n",
    "classifier.fit(X, y)\n",
    "y_pred=classifier.predict(X_test)\n",
    "viz=RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "tpr_gb=interp_tpr\n",
    "auc_gb=viz.roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c23bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Support Vector Classification on test set\n",
    "\n",
    "classifier = SVC\n",
    "classifier.fit(X, y)\n",
    "y_pred=classifier.predict(X_test)\n",
    "viz=RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "tpr_svc=interp_tpr\n",
    "auc_svc=viz.roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef1c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for XGBoost on test set\n",
    "\n",
    "classifier = XGB\n",
    "classifier.fit(X, y)\n",
    "y_pred=classifier.predict(X_test)\n",
    "viz=RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "tpr_xgb=interp_tpr\n",
    "auc_xgb=viz.roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e3e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for Voting Classifier on test set\n",
    "\n",
    "classifier = VotingClassifier(estimators = estimator, voting ='hard') \n",
    "classifier.fit(X, y)\n",
    "y_pred=classifier.predict(X_test)\n",
    "viz=RocCurveDisplay.from_predictions(y_test, y_pred)\n",
    "interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "interp_tpr[0] = 0.0\n",
    "tpr_vote=interp_tpr\n",
    "auc_vote=viz.roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e853aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,9))\n",
    "plt.rcParams[\"font.family\"] = \"Times\"\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    tpr_gb,\n",
    "    color=\"red\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"GB\", round(auc_gb, 2)),\n",
    "    lw=3.5,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    tpr_xgb,\n",
    "    color=\"green\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"XGB\", round(auc_xgb, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    tpr_svc,\n",
    "    color=\"blue\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"SVM\", round(auc_svc, 2)),\n",
    "    lw=3,\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    tpr_vote,\n",
    "    color=\"gold\",\n",
    "    label=\"%s (AUC=%.2f)\" % (\"HVE\", round(auc_vote, 2)),\n",
    "    lw=2.5,\n",
    "    alpha=0.8, \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 24)\n",
    "plt.ylabel('True Positive Rate', fontsize = 24)\n",
    "plt.legend(loc=\"lower right\", prop={'size':24})\n",
    "plt.tick_params(axis='both', which='major', labelsize=20)\n",
    "plt.savefig(\"tuned_models_test2.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
